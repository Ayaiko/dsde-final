{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd8b47b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76dba389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grain\\AppData\\Local\\Temp\\ipykernel_26024\\688514943.py:1: DtypeWarning: Columns (8,9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/processed/traffy_merged.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/processed/traffy_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4581c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (651600, 70)\n"
     ]
    }
   ],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "df['pm25'] = pd.to_numeric(df['pm25'], errors='coerce')\n",
    "df['pm10'] = pd.to_numeric(df['pm10'], errors='coerce')\n",
    "df['o3'] = pd.to_numeric(df['o3'], errors='coerce')\n",
    "df['no2'] = pd.to_numeric(df['no2'], errors='coerce')\n",
    "\n",
    "df['type'] = df['type_list'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format='mixed', utc=True)\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "\n",
    "district_encoded = pd.get_dummies(df['district'], prefix='district')\n",
    "df = pd.concat([df, district_encoded], axis=1)\n",
    "\n",
    "print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31feb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 24 binary target columns\n"
     ]
    }
   ],
   "source": [
    "all_types = set()\n",
    "for type_list in df['type']:\n",
    "    all_types.update(type_list)\n",
    "all_types = sorted(list(all_types))\n",
    "\n",
    "for t in all_types:\n",
    "    df[f'type_{t}'] = df['type'].apply(lambda x: 1 if t in x else 0)\n",
    "\n",
    "df = df.drop(['comment', 'coords', 'subdistrict', 'district', 'province', 'type', 'type_list', 'date'], axis=1)\n",
    "\n",
    "print(f\"Created {len(all_types)} binary target columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6818bb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Class Distribution for All Complaint Types\n",
      "================================================================================\n",
      "       type  count  percentage\n",
      "        ถนน 142104   21.808471\n",
      "    ทางเท้า 101322   15.549724\n",
      "ความปลอดภัย  66055   10.137354\n",
      "   แสงสว่าง  57715    8.857428\n",
      "    กีดขวาง  56902    8.732658\n",
      "  ความสะอาด  53568    8.220994\n",
      "      จราจร  41069    6.302793\n",
      "    น้ำท่วม  35979    5.521639\n",
      "ท่อระบายน้ำ  35583    5.460866\n",
      "       ป้าย  32687    5.016421\n",
      "  ร้องเรียน  31596    4.848987\n",
      "      สะพาน  27306    4.190608\n",
      "     ต้นไม้  24145    3.705494\n",
      "      สายไฟ  22496    3.452425\n",
      " เสียงรบกวน  22345    3.429251\n",
      "       คลอง  17743    2.722990\n",
      " สัตว์จรจัด  10836    1.662983\n",
      "    คนจรจัด   6275    0.963014\n",
      "      PM2.5   5580    0.856354\n",
      "     สอบถาม   3729    0.572284\n",
      "    เสนอแนะ   2709    0.415746\n",
      " การเดินทาง   1879    0.288367\n",
      "    ห้องน้ำ   1306    0.200430\n",
      "  ป้ายจราจร   1237    0.189840\n",
      "\n",
      "Total samples: 651,600\n",
      "Total complaint types: 24\n"
     ]
    }
   ],
   "source": [
    "type_cols = [c for c in df.columns if c.startswith('type_')]\n",
    "type_distribution = []\n",
    "\n",
    "for col in type_cols:\n",
    "    count = df[col].sum()\n",
    "    pct = (count / len(df)) * 100\n",
    "    type_name = col.replace('type_', '')\n",
    "    type_distribution.append({'type': type_name, 'count': count, 'percentage': pct})\n",
    "\n",
    "dist_df = pd.DataFrame(type_distribution).sort_values('count', ascending=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Class Distribution for All Complaint Types\")\n",
    "print(\"=\"*80)\n",
    "print(dist_df.to_string(index=False))\n",
    "print(f\"\\nTotal samples: {len(df):,}\")\n",
    "print(f\"Total complaint types: {len(type_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70a30c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: type_ถนน\n",
      "Original - Positive: 142,104 (21.81%)\n",
      "Original - Negative: 509,496 (78.19%)\n",
      "Minority ratio: 0.2181\n",
      "\n",
      "⚙ Using SMOTE + aggressive undersampling\n",
      "\n",
      "After Resampling:\n",
      "Positive: 254,748 (41.18%)\n",
      "Negative: 363,925 (58.82%)\n",
      "Total samples: 618,673 (was 651,600)\n",
      "\n",
      "✓ Balanced dataset ready for training\n",
      "Train - Positive: 203,762, Negative: 291,176\n",
      "Test - Positive: 50,986, Negative: 72,749\n",
      "\n",
      "After Resampling:\n",
      "Positive: 254,748 (41.18%)\n",
      "Negative: 363,925 (58.82%)\n",
      "Total samples: 618,673 (was 651,600)\n",
      "\n",
      "✓ Balanced dataset ready for training\n",
      "Train - Positive: 203,762, Negative: 291,176\n",
      "Test - Positive: 50,986, Negative: 72,749\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "target_type = 'type_ถนน'\n",
    "\n",
    "text_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "datetime_cols = df.select_dtypes(include=['datetime64']).columns.tolist()\n",
    "exclude = text_cols + datetime_cols + ['timestamp'] + [c for c in df.columns if c.startswith('type_')]\n",
    "\n",
    "X = df[[c for c in df.columns if c not in exclude]].select_dtypes(include=[np.number]).fillna(0)\n",
    "y = df[target_type]\n",
    "\n",
    "print(f\"Target: {target_type}\")\n",
    "print(f\"Original - Positive: {y.sum():,} ({y.sum()/len(y)*100:.2f}%)\")\n",
    "print(f\"Original - Negative: {(y==0).sum():,} ({(y==0).sum()/len(y)*100:.2f}%)\")\n",
    "\n",
    "minority_ratio = y.sum() / len(y)\n",
    "print(f\"Minority ratio: {minority_ratio:.4f}\")\n",
    "\n",
    "try:\n",
    "    if minority_ratio < 0.01:\n",
    "        # For very imbalanced data, only use SMOTE to bring minority to 10% of majority\n",
    "        print(\"\\n⚠ Severely imbalanced - using SMOTE only\")\n",
    "        smote = SMOTE(random_state=42, k_neighbors=min(5, y.sum()-1), sampling_strategy=0.1)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    elif minority_ratio < 0.05:\n",
    "        # Moderately imbalanced - SMOTE to 20% then undersample to 30%\n",
    "        print(\"\\n⚙ Using SMOTE + moderate undersampling\")\n",
    "        smote = SMOTE(random_state=42, k_neighbors=5, sampling_strategy=0.2)\n",
    "        under = RandomUnderSampler(random_state=42, sampling_strategy=0.3)\n",
    "        pipeline = ImbPipeline([('smote', smote), ('under', under)])\n",
    "        X_resampled, y_resampled = pipeline.fit_resample(X, y)\n",
    "    else:\n",
    "        # Less imbalanced - SMOTE + aggressive undersampling\n",
    "        print(\"\\n⚙ Using SMOTE + aggressive undersampling\")\n",
    "        smote = SMOTE(random_state=42, k_neighbors=5, sampling_strategy=0.5)\n",
    "        under = RandomUnderSampler(random_state=42, sampling_strategy=0.7)\n",
    "        pipeline = ImbPipeline([('smote', smote), ('under', under)])\n",
    "        X_resampled, y_resampled = pipeline.fit_resample(X, y)\n",
    "    \n",
    "    print(f\"\\nAfter Resampling:\")\n",
    "    print(f\"Positive: {y_resampled.sum():,} ({y_resampled.sum()/len(y_resampled)*100:.2f}%)\")\n",
    "    print(f\"Negative: {(y_resampled==0).sum():,} ({(y_resampled==0).sum()/len(y_resampled)*100:.2f}%)\")\n",
    "    print(f\"Total samples: {len(y_resampled):,} (was {len(y):,})\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "    print(f\"\\n✓ Balanced dataset ready for training\")\n",
    "    print(f\"Train - Positive: {y_train.sum():,}, Negative: {(y_train==0).sum():,}\")\n",
    "    print(f\"Test - Positive: {y_test.sum():,}, Negative: {(y_test==0).sum():,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n⚠ Resampling failed: {e}\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    print(\"Using original imbalanced data with stratified split + class_weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42bee4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RandomizedSearchCV...\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "\n",
      "============================================================\n",
      "Best Parameters:\n",
      "============================================================\n",
      "class_weight: balanced\n",
      "max_depth: 38\n",
      "max_features: None\n",
      "min_samples_leaf: 3\n",
      "min_samples_split: 9\n",
      "n_estimators: 288\n",
      "\n",
      "Best CV F1 Score: 0.5232\n",
      "\n",
      "✓ Training complete with optimized parameters\n",
      "\n",
      "============================================================\n",
      "Best Parameters:\n",
      "============================================================\n",
      "class_weight: balanced\n",
      "max_depth: 38\n",
      "max_features: None\n",
      "min_samples_leaf: 3\n",
      "min_samples_split: 9\n",
      "n_estimators: 288\n",
      "\n",
      "Best CV F1 Score: 0.5232\n",
      "\n",
      "✓ Training complete with optimized parameters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define parameter distributions (continuous ranges)\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 501),  # Uniform distribution from 100 to 500\n",
    "    'max_depth': randint(10, 51),  # Uniform distribution from 10 to 50\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 5),\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "print(\"Starting RandomizedSearchCV...\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf, \n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,  # Number of parameter settings sampled\n",
    "    cv=2,  # 3-fold cross-validation\n",
    "    scoring='f1',  # Optimize for F1 score\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=3\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Best Parameters:\")\n",
    "print(\"=\"*60)\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "print(f\"\\nBest CV F1 Score: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Use best model\n",
    "model = random_search.best_estimator_\n",
    "print(\"\\n✓ Training complete with optimized parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb55010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Model Performance: type_การเดินทาง\n",
      "============================================================\n",
      "Accuracy: 0.5805\n",
      "Precision: 0.4926\n",
      "Recall: 0.6000\n",
      "F1: 0.5410\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Not การเดินทาง       0.67      0.57      0.61     72749\n",
      "    การเดินทาง       0.49      0.60      0.54     50986\n",
      "\n",
      "      accuracy                           0.58    123735\n",
      "     macro avg       0.58      0.58      0.58    123735\n",
      "  weighted avg       0.60      0.58      0.58    123735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Model Performance: type_การเดินทาง\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred, zero_division=0):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, zero_division=0):.4f}\")\n",
    "print(f\"F1: {f1_score(y_test, y_pred, zero_division=0):.4f}\")\n",
    "print(\"\\n\" + classification_report(y_test, y_pred, target_names=['Not การเดินทาง', 'การเดินทาง']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72391b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 651600 entries, 0 to 651599\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   pm25         651600 non-null  float64\n",
      " 1   pm10         651600 non-null  float64\n",
      " 2   o3           651600 non-null  float64\n",
      " 3   no2          651600 non-null  float64\n",
      " 4   hour         651600 non-null  int32  \n",
      " 5   day_of_week  651600 non-null  int32  \n",
      " 6   month        651600 non-null  int32  \n",
      " 7   hour_sin     651600 non-null  float64\n",
      " 8   hour_cos     651600 non-null  float64\n",
      " 9   day_sin      651600 non-null  float64\n",
      " 10  day_cos      651600 non-null  float64\n",
      "dtypes: float64(8), int32(3)\n",
      "memory usage: 47.2 MB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "861a0618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Top 10 Factors Affecting type_การเดินทาง\n",
      "============================================================\n",
      "    feature  importance\n",
      "   hour_sin    0.175511\n",
      "   hour_cos    0.149521\n",
      "       pm25    0.123423\n",
      "       pm10    0.113733\n",
      "       hour    0.110488\n",
      "         o3    0.097769\n",
      "        no2    0.064648\n",
      "      month    0.051365\n",
      "    day_sin    0.044763\n",
      "day_of_week    0.038911\n"
     ]
    }
   ],
   "source": [
    "importance_df = pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Top 10 Factors Affecting type_การเดินทาง\")\n",
    "print(\"=\"*60)\n",
    "print(importance_df.head(10).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsde-cedt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
